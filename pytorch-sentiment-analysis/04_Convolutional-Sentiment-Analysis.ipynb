{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Convolutional-Sentiment-Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGpy3rvL1_5",
        "outputId": "2766447c-0405-4488-ec3e-b55bbd627f81"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import torchtext\r\n",
        "from torchtext.legacy import data, datasets\r\n",
        "\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "import spacy\r\n",
        "\r\n",
        "\r\n",
        "torch.__version__, torchtext.__version__, spacy.__version__, np.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.8.0+cu101', '0.9.0', '2.2.4', '1.19.5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I39JKY87WzB9"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xmBt5IAbCKq",
        "outputId": "c86b7d71-c3bb-4d22-a6dd-480f50d3e15b"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "# set random seed for reproducibility\r\n",
        "SEED = 1234\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "# download and split dataset (train, valid, test)\r\n",
        "TEXT = data.Field(\r\n",
        "    tokenize='spacy', tokenizer_language='en_core_web_sm', batch_first=True\r\n",
        ")\r\n",
        "LABEL = data.LabelField(dtype=torch.float)\r\n",
        "\r\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\r\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:05<00:00, 14.4MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 2s, sys: 16.5 s, total: 2min 18s\n",
            "Wall time: 2min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es19mu23RL4j",
        "outputId": "1e8ca25b-187f-4d16-8ffc-6a8ab45e16c4"
      },
      "source": [
        "# check the type and size of dataset\r\n",
        "print(f'>>> type : {type(train_data)}')\r\n",
        "print(f'>>> Number of training examples: {len(train_data)}')   # 17500 (35%)\r\n",
        "print(f'>>> Number of validation examples: {len(valid_data)}') # 7500  (15%)\r\n",
        "print(f'>>> Number of testing examples: {len(test_data)}')     # 25000 (50%)\r\n",
        "print()\r\n",
        "\r\n",
        "# check one sample data\r\n",
        "tmp_ex = train_data.examples[0]\r\n",
        "tmp_dict = vars(tmp_ex)\r\n",
        "print('< example data >')\r\n",
        "print('>>> type :', type(tmp_ex))\r\n",
        "for key in tmp_dict:\r\n",
        "  print(f'>>> {key} : {tmp_dict[key]}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> type : <class 'torchtext.legacy.data.dataset.Dataset'>\n",
            ">>> Number of training examples: 17500\n",
            ">>> Number of validation examples: 7500\n",
            ">>> Number of testing examples: 25000\n",
            "\n",
            "< example data >\n",
            ">>> type : <class 'torchtext.legacy.data.example.Example'>\n",
            ">>> text : ['JUST', 'CAUSE', 'showcases', 'Sean', 'Connery', 'as', 'a', 'Harvard', 'law', 'prof', ',', 'Kate', 'Capshaw', '(', 'does', 'she', 'still', 'get', 'work', '?', ')', 'as', 'his', 'wife', '(', 'slight', 'age', 'difference', ')', 'and', 'Lawrence', 'Fishburne', 'as', 'a', 'racist', 'southern', 'cop', '(', '!', ')', 'and', 'Ed', 'Harris', 'in', 'a', 'totally', 'over', 'the', 'top', 'rendition', 'of', 'a', 'fundamentalist', 'southern', 'serial', 'killer.<br', '/><br', '/>Weird', 'casting', ',', 'but', 'the', 'movie', 'plays', 'serious', 'mindf', '*', '*', 'with', 'the', 'audience', '.', '(', 'do', \"n't\", 'read', 'if', 'you', 'ever', 'intend', 'to', 'seriously', 'watch', 'this', 'film', 'or', 'to', 'ever', 'watch', 'this', 'film', 'seriously', 'due', 'to', 'the', 'spoilers', ')', 'First', 'of', 'all', ',', 'I', 'felt', 'myself', 'rolling', 'my', 'eyes', 'repeatedly', 'at', 'the', 'Liberal', 'stereotypes', ':', 'the', 'cops', 'are', 'all', 'sadistic', 'and', 'frame', 'this', 'black', 'guy', 'with', 'no', 'evidence', '.', 'The', 'coroner', ',', 'witnesses', 'and', 'even', 'the', 'lawyer', 'of', 'the', 'accused', 'collaborate', 'against', 'him', '(', 'he', 'is', 'accused', 'of', 'the', 'rape', 'and', 'murder', 'of', 'a', 'young', 'girl', ')', 'because', 'he', 'is', 'black.<br', '/><br', '/>Connery', 'is', 'a', 'Harvard', 'law', 'prof', 'who', 'gives', 'impassioned', 'speeches', 'about', 'the', 'injustices', 'against', 'blacks', 'and', 'against', 'the', 'barbarous', 'death', 'penalty', '.', 'He', 'is', 'approached', 'by', 'the', 'convicted', 'man', \"'s\", 'grandmother', 'to', 'defend', 'him', 'and', 're', '-', 'open', 'the', 'trial.<br', '/><br', '/>Connery', 'is', 'stonewalled', '(', 'yawn', '...', ')', 'by', 'the', 'small', 'town', 'officials', 'and', 'the', 'good', 'IL', \"'\", 'boys', 'club', 'but', 'finds', 'that', 'the', 'case', 'against', 'Blair', ',', 'the', 'alleged', 'killer', ',', 'now', 'on', 'death', 'row', ',', 'was', 'all', 'fabricated', '.', 'The', 'main', 'evidence', 'was', 'his', 'confession', 'which', 'was', 'beaten', 'out', 'of', 'him.<br', '/><br', '/>The', 'beating', 'was', 'administered', 'by', 'a', 'black', 'cop', '(', '!', ')', 'who', 'even', 'played', 'Russian', 'roulette', 'to', 'get', 'the', 'confession', 'out', 'of', 'him', '.', 'Connery', 'finds', 'out', 'that', 'another', 'inmate', 'on', 'death', 'row', 'actually', 'did', 'the', 'murder', 'and', 'after', 'a', 'few', 'tete', 'a', 'tetes', 'with', 'a', 'seriously', 'overacting', ',', 'Hannibal', 'Lecter', '-', 'like', 'Ed', 'Harris', ',', 'he', 'finds', 'out', 'where', 'Harris', 'hid', 'the', 'murder', 'weapon.<br', '/><br', '/>He', 'gets', 'a', 're', '-', 'trial', 'and', 'Blair', 'is', 'freed.<br', '/><br', '/>I', 'think', '...', 'film', 'over', '....', '<br', '/><br', '/>Then', 'suddenly', '!', 'It', 'turns', 'out', 'that', 'Blair', 'IS', 'a', 'psychotic', 'psycho', 'and', 'that', 'he', 'used', '\"', 'white', 'guilt', '\"', 'to', 'enlist', 'Connery', '.', 'He', 'concocted', 'the', 'story', 'with', 'Ed', 'Harris', 'in', 'return', 'for', 'Blair', 'carrying', 'out', 'a', 'few', 'murders', 'for', 'Harris.<br', '/><br', '/>now', 'Blair', 'is', 'on', 'the', 'loose', 'again', ',', 'thanks', 'to', 'Connery', \"'s\", 'deluded', 'PC', 'principles', '!', 'The', 'final', '30', 'min', '.', 'are', 'a', 'weird', 'action', 'movie', 'tacked', 'onto', 'a', 'legal', 'drama', ',', 'Connery', 'and', 'Fishburne', 'fighting', 'the', 'serial', 'killer', 'in', 'an', 'alligator', 'skinning', 'house', 'on', 'stilts', '(', 'yes', ',', 'you', 'read', 'that', 'right', ')', 'in', 'the', 'everglades.<br', '/><br', '/>That', 'was', 'one', 'weird', 'film.<br', '/><br', '/>So', 'the', 'whole', 'system', 'is', 'corrupt', 'and', 'inefficient', ',', 'the', 'cops', 'are', 'all', 'just', 'bullies', 'and', 'Abu', 'Graib', 'type', 'torturers', ',', 'but', 'the', 'criminals', 'are', 'really', 'psychotics', 'and', 'deserve', 'to', 'fry.<br', '/><br', '/>Truly', 'depressing', 'on', 'every', 'level', '!', 'The', 'system', 'is', 'completely', 'rotten', 'and', 'the', 'PC', 'white', 'guilt', 'types', 'who', 'challenge', 'it', 'are', 'seriously', 'deluded', 'too.<br', '/><br', '/>Two', 'thumbs', 'down', '.', 'Connery', 'obviously', 'had', 'to', 'make', 'a', 'mortgage', 'payment', 'or', 'something', '.']\n",
            ">>> label : neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVOnakpiP1T-",
        "outputId": "d1d14f49-420b-4040-b987-80ec483ff9d4"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "# build vocabulary\r\n",
        "MAX_VOCAB_SIZE = 25_000\r\n",
        "TEXT.build_vocab(train_data, \r\n",
        "                 max_size = MAX_VOCAB_SIZE, \r\n",
        "                 vectors = \"glove.6B.100d\", \r\n",
        "                 unk_init = torch.Tensor.normal_)\r\n",
        "LABEL.build_vocab(train_data)\r\n",
        "\r\n",
        "print('\\n')\r\n",
        "print(f\">>> Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\r\n",
        "print(f\">>> Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\r\n",
        "print(f\">>> Top 20 common tokens :{TEXT.vocab.freqs.most_common(20)}\")\r\n",
        "print()\r\n",
        "print('<itos and stoi>')\r\n",
        "print('>>> itos :', TEXT.vocab.itos[:10])\r\n",
        "print('>>> stoi :', LABEL.vocab.stoi)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399215/400000 [00:17<00:00, 23904.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            ">>> Unique tokens in TEXT vocabulary: 25002\n",
            ">>> Unique tokens in LABEL vocabulary: 2\n",
            ">>> Top 20 common tokens :[('the', 202538), (',', 192715), ('.', 165259), ('and', 109176), ('a', 108967), ('of', 101099), ('to', 93437), ('is', 76014), ('in', 61519), ('I', 54176), ('it', 53451), ('that', 49386), ('\"', 44430), (\"'s\", 43117), ('this', 42352), ('-', 37369), ('/><br', 35648), ('was', 35029), ('as', 30258), ('with', 29733)]\n",
            "\n",
            "<itos and stoi>\n",
            ">>> itos : ['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
            ">>> stoi : defaultdict(None, {'neg': 0, 'pos': 1})\n",
            "CPU times: user 41.9 s, sys: 8.43 s, total: 50.3 s\n",
            "Wall time: 3min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "vB58J1OUQZXr",
        "outputId": "2160e4d5-7400-447d-ba58-95f354658e94"
      },
      "source": [
        "# create the iterators\r\n",
        "BATCH_SIZE = 64\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device\r\n",
        ")\r\n",
        "\r\n",
        "display(device, type(train_iterator), len(train_iterator), len(train_data)/BATCH_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torchtext.legacy.data.iterator.BucketIterator"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "273.4375"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Ulm3zW3hX"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDyjWvlThyW-"
      },
      "source": [
        "class CNN(nn.Module):\r\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, n_filters, filter_sizes, output_dim, dropout):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\r\n",
        "    self.conv_0 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\r\n",
        "    self.conv_1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\r\n",
        "    self.conv_2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\r\n",
        "    self.dropout = nn.Dropout(dropout)\r\n",
        "    self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\r\n",
        "  \r\n",
        "  def forward(self, text):\r\n",
        "    # text = [batch size, sent len]\r\n",
        "    print(text.shape)\r\n",
        "\r\n",
        "    embedded = self.embedding(text)\r\n",
        "    embedded = embedded.unsqueeze(1)\r\n",
        "    # embedded = [batch size, 1, sent len, emb dim]\r\n",
        "    print(embedded.shape)\r\n",
        "\r\n",
        "    conv0 = F.relu(self.conv_0(embedded).squeeze(3))\r\n",
        "    conv1 = F.relu(self.conv_1(embedded).squeeze(3))\r\n",
        "    conv2 = F.relu(self.conv_2(embedded).squeeze(3))\r\n",
        "    # conv = [batch size, n_filters, sent len-filter_sizes[n]+1]\r\n",
        "    print(conv0.shape, conv1.shape, conv2.shape)\r\n",
        "\r\n",
        "    pool0 = F.max_pool1d(conv0, conv0.shape[2]).squeeze(2)\r\n",
        "    pool1 = F.max_pool1d(conv1, conv1.shape[2]).squeeze(2)\r\n",
        "    pool2 = F.max_pool1d(conv2, conv2.shape[2]).squeeze(2)\r\n",
        "    # pool = [batch size, n_filters]\r\n",
        "    print(pool0.shape, pool1.shape, pool2.shape)\r\n",
        "\r\n",
        "    cat = self.dropout(torch.cat((pool0, pool1, pool2), dim=1))\r\n",
        "    # cat = [batch size, n_filters*len(filter_sizes)]\r\n",
        "    print(cat.shape)\r\n",
        "\r\n",
        "    out = self.fc(cat)\r\n",
        "    # out = [batch size, output dim]\r\n",
        "    print(out.shape)\r\n",
        "    \r\n",
        "    return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHH2INtyw-ih",
        "outputId": "04dc3be7-8fb8-4ebe-d43c-d6e720196fd0"
      },
      "source": [
        "# shape test code\r\n",
        "model = CNN(25000, 100, 0, 64, (3, 4, 5), 1, 0.5)\r\n",
        "\r\n",
        "arr = torch.randint(low=0, high=25000, size=(1, 10), dtype=torch.long)\r\n",
        "if 0 in arr: print(arr)\r\n",
        "model(arr).sigmoid()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n",
            "torch.Size([1, 1, 10, 100])\n",
            "torch.Size([1, 64, 8]) torch.Size([1, 64, 7]) torch.Size([1, 64, 6])\n",
            "torch.Size([1, 64]) torch.Size([1, 64]) torch.Size([1, 64])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6591]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWWFdHzChySQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}