{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Convolutional-Sentiment-Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGpy3rvL1_5",
        "outputId": "36369da7-7d01-4657-d090-278197162f3d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data, datasets\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import spacy\n",
        "\n",
        "\n",
        "torch.__version__, torchtext.__version__, spacy.__version__, np.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.8.0+cu101', '0.9.0', '2.2.4', '1.19.5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I39JKY87WzB9"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xmBt5IAbCKq",
        "outputId": "4e980c62-77b6-4eba-fc09-6e1c3452951b"
      },
      "source": [
        "%%time\n",
        "\n",
        "# set random seed for reproducibility\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# download and split dataset (train, valid, test)\n",
        "TEXT = data.Field(\n",
        "    tokenize='spacy', tokenizer_language='en_core_web_sm', batch_first=True\n",
        ")\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:04<00:00, 16.8MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 46s, sys: 11.4 s, total: 1min 57s\n",
            "Wall time: 2min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es19mu23RL4j",
        "outputId": "d0b2bc52-0c38-4589-de50-79928451f97a"
      },
      "source": [
        "# check the type and size of dataset\n",
        "print(f'>>> type : {type(train_data)}')\n",
        "print(f'>>> Number of training examples: {len(train_data)}')   # 17500 (35%)\n",
        "print(f'>>> Number of validation examples: {len(valid_data)}') # 7500  (15%)\n",
        "print(f'>>> Number of testing examples: {len(test_data)}')     # 25000 (50%)\n",
        "print()\n",
        "\n",
        "# check one sample data\n",
        "tmp_ex = train_data.examples[0]\n",
        "tmp_dict = vars(tmp_ex)\n",
        "print('< example data >')\n",
        "print('>>> type :', type(tmp_ex))\n",
        "for key in tmp_dict:\n",
        "  print(f'>>> {key} : {tmp_dict[key]}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> type : <class 'torchtext.legacy.data.dataset.Dataset'>\n",
            ">>> Number of training examples: 17500\n",
            ">>> Number of validation examples: 7500\n",
            ">>> Number of testing examples: 25000\n",
            "\n",
            "< example data >\n",
            ">>> type : <class 'torchtext.legacy.data.example.Example'>\n",
            ">>> text : ['I', 'picked', 'up', 'this', 'movie', 'with', 'the', 'intention', 'of', 'getting', 'a', 'bad', 'zombie', 'movie', '.', 'But', 'I', 'had', 'no', 'Idea', 'what', 'I', 'was', 'getting', 'myself', 'into.<br', '/><br', '/>I', 'started', 'the', 'movie', 'and', 'soon', 'I', 'had', 'been', 'pulled', 'into', 'a', 'world', 'of', 'pain', 'and', 'visual', 'torture.<br', '/><br', '/>I', 'finally', 'know', 'what', 'hell', 'is', 'like', '.', 'It', \"'s\", 'this', 'movie', '.', 'For', 'eternity', '.', 'This', 'movie', 'has', 'no', 'value', '.', 'It', 'did', \"n't\", 'even', 'really', 'have', 'a', 'plot', '.', 'There', 'was', 'stuff', 'going', 'on', 'in', 'each', 'scene', 'but', 'no', 'overall', 'explanation', 'why', 'anything', 'happens.<br', '/><br', '/>Instead', 'of', 'watching', 'this', 'movie', 'I', 'suggest', 'that', 'you', 'line', 'the', 'nearest', 'blender', 'with', 'oil', 'and', 'try', 'and', 'stuff', 'as', 'many', 'bullets', 'in', 'it', 'as', 'you', 'can', '.', 'You', 'will', 'find', 'that', 'the', 'outcome', 'to', 'be', 'far', 'more', 'pleasant', 'than', 'this', 'movie.<br', '/><br', \"/>Don't\", 'even', 'watch', 'it', '.', 'Not', 'even', 'to', 'see', 'how', 'bad', 'it', 'is', '.', 'I', 'beg', 'you', '.', 'If', 'you', 'watch', 'it', ',', 'then', 'it', 'means', 'they', 'win', '.']\n",
            ">>> label : neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVOnakpiP1T-",
        "outputId": "5ef20585-5666-40bc-a1d4-220136ec0da5"
      },
      "source": [
        "%%time\n",
        "\n",
        "# build vocabulary\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print('\\n')\n",
        "print(f\">>> Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\">>> Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "print(f\">>> Top 20 common tokens :{TEXT.vocab.freqs.most_common(20)}\")\n",
        "print()\n",
        "print('<itos and stoi>')\n",
        "print('>>> itos :', TEXT.vocab.itos[:10])\n",
        "print('>>> stoi :', LABEL.vocab.stoi)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.36MB/s]                           \n",
            "100%|█████████▉| 399327/400000 [00:17<00:00, 22239.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            ">>> Unique tokens in TEXT vocabulary: 25002\n",
            ">>> Unique tokens in LABEL vocabulary: 2\n",
            ">>> Top 20 common tokens :[('the', 201993), (',', 191745), ('.', 165579), ('a', 109448), ('and', 109088), ('of', 100491), ('to', 93934), ('is', 76276), ('in', 61212), ('I', 54529), ('it', 53813), ('that', 49139), ('\"', 44507), (\"'s\", 43358), ('this', 42274), ('-', 37014), ('/><br', 35725), ('was', 34912), ('as', 30434), ('movie', 29970)]\n",
            "\n",
            "<itos and stoi>\n",
            ">>> itos : ['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n",
            ">>> stoi : defaultdict(None, {'neg': 0, 'pos': 1})\n",
            "CPU times: user 40.4 s, sys: 5.11 s, total: 45.5 s\n",
            "Wall time: 3min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "vB58J1OUQZXr",
        "outputId": "4d6097cb-3708-44f5-9346-62635efb80f1"
      },
      "source": [
        "# create the iterators\n",
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device\n",
        ")\n",
        "\n",
        "display(device, type(train_iterator), len(train_iterator), len(train_data)/BATCH_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torchtext.legacy.data.iterator.BucketIterator"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "273.4375"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Ulm3zW3hX"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDyjWvlThyW-"
      },
      "source": [
        "# CNN model for fixed convolutional layers (3, 4, 5)\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.conv_0 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
        "    self.conv_1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
        "    self.conv_2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
        "  \n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "\n",
        "    embedded = self.embedding(text_ts)\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    # embedded = [batch size, 1, sent len, emb dim]\n",
        "\n",
        "    conv0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
        "    conv1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
        "    conv2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
        "    # conv = [batch size, n_filters, sent len-filter_sizes[n]+1]\n",
        "\n",
        "    pool0 = F.max_pool1d(conv0, conv0.shape[2]).squeeze(2)\n",
        "    pool1 = F.max_pool1d(conv1, conv1.shape[2]).squeeze(2)\n",
        "    pool2 = F.max_pool1d(conv2, conv2.shape[2]).squeeze(2)\n",
        "    # pool = [batch size, n_filters]\n",
        "\n",
        "    cat = self.dropout(torch.cat((pool0, pool1, pool2), dim=1))\n",
        "    # cat = [batch size, n_filters*len(filter_sizes)]\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, output dim]\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOH7cgxzqDDR",
        "outputId": "de3bda26-cf98-4090-e0d1-45b69f14b2e7"
      },
      "source": [
        "# function for model summary\n",
        "def model_summary(model):\n",
        "  num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  print(f'>>> The model has {num_parameters:,} trainable parameters')\n",
        "  print(model)\n",
        "\n",
        "\n",
        "# generate model & summary\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100  # 50-250\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]  # '<pad>' -> 1\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "OUTPUT_DIM = 1  # No of labels\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "model_summary(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (conv_0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "  (conv_1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "  (conv_2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imsBloKKqDDX",
        "outputId": "cabc3e23-3d89-4cd9-816a-742924f5e044"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).unsqueeze(1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.conv_0(ts).squeeze(-1)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.avg_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 1, 12, 100])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5169],\n",
              "        [0.4944]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWWFdHzChySQ"
      },
      "source": [
        "# CNN model for flexible convolutional layers\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.convs = nn.ModuleList([nn.Conv2d(1, n_filters, (fsize, embedding_dim)) for fsize in filter_sizes])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_filters*len(filter_sizes), output_dim)\n",
        "  \n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "    \n",
        "    embedded = self.embedding(text_ts).unsqueeze(1)\n",
        "    # [batch size, 1, sent len, emb dim]\n",
        "\n",
        "    conved = [F.relu(conv(embedded)).squeeze(-1) for conv in self.convs]\n",
        "    # conved = [batch size, n_filters, sent len - filter size + 1]\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[-1]).squeeze(-1) for conv in conved]\n",
        "    # pooled = [batch size, n_filters]\n",
        "\n",
        "    cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "    # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, 1]\n",
        "\n",
        "    return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYqx53PV2mx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abad2e7-b914-4aa8-e386-79c96ee10f84"
      },
      "source": [
        "# generate model & summary\n",
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "model_summary(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrKpr7m8lh4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40724002-4753-4e1f-a2be-1ca18164c4c2"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).unsqueeze(1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.convs[0](ts).squeeze(-1)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.avg_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 1, 12, 100])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5159],\n",
              "        [0.5477]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA-hnGUOW4C8"
      },
      "source": [
        "# 1-Dimensional CNN model for flexible convolutional layers\n",
        "class CNN1d(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, output_dim, n_filters, filter_sizes, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.convs = nn.ModuleList([nn.Conv1d(in_channels=embedding_dim, out_channels=n_filters, kernel_size=fs)\n",
        "                                for fs in filter_sizes])\n",
        "    self.droptout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
        "\n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "\n",
        "    embedded = self.embedding(text_ts).permute(0, 2, 1)\n",
        "    # embedded = [batch size, emb dim, sent len]\n",
        "\n",
        "    conved = [conv(embedded) for conv in self.convs]\n",
        "    # conved = [batch size, n_filters, sent len - filter_sizes[0] + 1]\n",
        "\n",
        "    pooled = [F.max_pool1d(c, c.shape[-1]).squeeze(-1) for c in conved]\n",
        "    # pooled = [batch size, n_filters]\n",
        "\n",
        "    cat = self.droptout(torch.cat(pooled, dim=1))\n",
        "    # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, 1]\n",
        "\n",
        "    return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47gb-Q3zFKgt",
        "outputId": "44fbbdae-7863-4af5-9924-8287547d9a7f"
      },
      "source": [
        "# generate model & summary\n",
        "model = CNN1d(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "model_summary(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN1d(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(100, 100, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (droptout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrxY79uFH6jd",
        "outputId": "421e9e6c-b338-41c1-d5e4-96eded35a368"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).permute(0, 2, 1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.convs[0](ts)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.avg_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 100, 12])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4947],\n",
              "        [0.5284]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "docsyRD_FKmo"
      },
      "source": [
        "# generate final model\n",
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "\n",
        "# load pre-trained embeddings\n",
        "model.embedding.weight.data.copy_ = TEXT.vocab.vectors\n",
        "\n",
        "# initialize unk & pad tokens to zero\n",
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJMD9JFJRFDR"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}