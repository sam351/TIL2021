{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Convolutional-Sentiment-Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGpy3rvL1_5",
        "outputId": "1dac3a4b-22f1-49f5-f0a2-dd5930bd0770"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data, datasets\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import spacy\n",
        "\n",
        "\n",
        "torch.__version__, torchtext.__version__, spacy.__version__, np.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.8.0+cu101', '0.9.0', '2.2.4', '1.19.5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I39JKY87WzB9"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xmBt5IAbCKq",
        "outputId": "46c55548-0e2a-4d11-bc26-89c208fbea86"
      },
      "source": [
        "%%time\n",
        "\n",
        "# set random seed for reproducibility\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# download and split dataset (train, valid, test)\n",
        "TEXT = data.Field(\n",
        "    tokenize='spacy', tokenizer_language='en_core_web_sm', batch_first=True\n",
        ")\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:05<00:00, 15.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 44s, sys: 10.8 s, total: 1min 55s\n",
            "Wall time: 2min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es19mu23RL4j",
        "outputId": "2e57c055-3fc2-4b7d-be1d-b02aecd69255"
      },
      "source": [
        "# check the type and size of dataset\n",
        "print(f'>>> type : {type(train_data)}')\n",
        "print(f'>>> Number of training examples: {len(train_data)}')   # 17500 (35%)\n",
        "print(f'>>> Number of validation examples: {len(valid_data)}') # 7500  (15%)\n",
        "print(f'>>> Number of testing examples: {len(test_data)}')     # 25000 (50%)\n",
        "print()\n",
        "\n",
        "# check one sample data\n",
        "tmp_ex = train_data.examples[0]\n",
        "tmp_dict = vars(tmp_ex)\n",
        "print('< example data >')\n",
        "print('>>> type :', type(tmp_ex))\n",
        "for key in tmp_dict:\n",
        "  print(f'>>> {key} : {tmp_dict[key]}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> type : <class 'torchtext.legacy.data.dataset.Dataset'>\n",
            ">>> Number of training examples: 17500\n",
            ">>> Number of validation examples: 7500\n",
            ">>> Number of testing examples: 25000\n",
            "\n",
            "< example data >\n",
            ">>> type : <class 'torchtext.legacy.data.example.Example'>\n",
            ">>> text : ['I', 'picked', 'up', 'this', 'movie', 'with', 'the', 'intention', 'of', 'getting', 'a', 'bad', 'zombie', 'movie', '.', 'But', 'I', 'had', 'no', 'Idea', 'what', 'I', 'was', 'getting', 'myself', 'into.<br', '/><br', '/>I', 'started', 'the', 'movie', 'and', 'soon', 'I', 'had', 'been', 'pulled', 'into', 'a', 'world', 'of', 'pain', 'and', 'visual', 'torture.<br', '/><br', '/>I', 'finally', 'know', 'what', 'hell', 'is', 'like', '.', 'It', \"'s\", 'this', 'movie', '.', 'For', 'eternity', '.', 'This', 'movie', 'has', 'no', 'value', '.', 'It', 'did', \"n't\", 'even', 'really', 'have', 'a', 'plot', '.', 'There', 'was', 'stuff', 'going', 'on', 'in', 'each', 'scene', 'but', 'no', 'overall', 'explanation', 'why', 'anything', 'happens.<br', '/><br', '/>Instead', 'of', 'watching', 'this', 'movie', 'I', 'suggest', 'that', 'you', 'line', 'the', 'nearest', 'blender', 'with', 'oil', 'and', 'try', 'and', 'stuff', 'as', 'many', 'bullets', 'in', 'it', 'as', 'you', 'can', '.', 'You', 'will', 'find', 'that', 'the', 'outcome', 'to', 'be', 'far', 'more', 'pleasant', 'than', 'this', 'movie.<br', '/><br', \"/>Don't\", 'even', 'watch', 'it', '.', 'Not', 'even', 'to', 'see', 'how', 'bad', 'it', 'is', '.', 'I', 'beg', 'you', '.', 'If', 'you', 'watch', 'it', ',', 'then', 'it', 'means', 'they', 'win', '.']\n",
            ">>> label : neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVOnakpiP1T-",
        "outputId": "2fc38611-d694-424c-d10d-e2677bfa6267"
      },
      "source": [
        "%%time\n",
        "\n",
        "# build vocabulary\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print('\\n')\n",
        "print(f\">>> Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\">>> Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "print(f\">>> Top 20 common tokens :{TEXT.vocab.freqs.most_common(20)}\")\n",
        "print()\n",
        "print('<itos and stoi>')\n",
        "print('>>> itos :', TEXT.vocab.itos[:10])\n",
        "print('>>> stoi :', LABEL.vocab.stoi)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 398496/400000 [00:17<00:00, 23232.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            ">>> Unique tokens in TEXT vocabulary: 25002\n",
            ">>> Unique tokens in LABEL vocabulary: 2\n",
            ">>> Top 20 common tokens :[('the', 201993), (',', 191745), ('.', 165579), ('a', 109448), ('and', 109088), ('of', 100491), ('to', 93934), ('is', 76276), ('in', 61212), ('I', 54529), ('it', 53813), ('that', 49139), ('\"', 44507), (\"'s\", 43358), ('this', 42274), ('-', 37014), ('/><br', 35725), ('was', 34912), ('as', 30434), ('movie', 29970)]\n",
            "\n",
            "<itos and stoi>\n",
            ">>> itos : ['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n",
            ">>> stoi : defaultdict(None, {'neg': 0, 'pos': 1})\n",
            "CPU times: user 40.4 s, sys: 7.33 s, total: 47.8 s\n",
            "Wall time: 3min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "vB58J1OUQZXr",
        "outputId": "000f77f7-af1f-4cba-bc10-69f32baee8fb"
      },
      "source": [
        "# create the iterators\n",
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device\n",
        ")\n",
        "\n",
        "display(device, type(train_iterator), len(train_iterator), len(train_data)/BATCH_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torchtext.legacy.data.iterator.BucketIterator"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "273.4375"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Ulm3zW3hX"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDyjWvlThyW-"
      },
      "source": [
        "# CNN model for fixed convolutional layers (3, 4, 5)\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.conv_0 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
        "    self.conv_1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
        "    self.conv_2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
        "  \n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "    # print(text_ts.shape)\n",
        "\n",
        "    embedded = self.embedding(text_ts)\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    # embedded = [batch size, 1, sent len, emb dim]\n",
        "    # print(embedded.shape)\n",
        "\n",
        "    conv0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
        "    conv1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
        "    conv2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
        "    # conv = [batch size, n_filters, sent len-filter_sizes[n]+1]\n",
        "    # print(conv0.shape, conv1.shape, conv2.shape)\n",
        "\n",
        "    pool0 = F.max_pool1d(conv0, conv0.shape[2]).squeeze(2)\n",
        "    pool1 = F.max_pool1d(conv1, conv1.shape[2]).squeeze(2)\n",
        "    pool2 = F.max_pool1d(conv2, conv2.shape[2]).squeeze(2)\n",
        "    # pool = [batch size, n_filters]\n",
        "    # print(pool0.shape, pool1.shape, pool2.shape)\n",
        "\n",
        "    cat = self.dropout(torch.cat((pool0, pool1, pool2), dim=1))\n",
        "    # cat = [batch size, n_filters*len(filter_sizes)]\n",
        "    # print(cat.shape)\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, output dim]\n",
        "    # print(out.shape)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOH7cgxzqDDR",
        "outputId": "7028fef7-1209-4aba-cdf6-4f1f630bc72b"
      },
      "source": [
        "# generate model\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100  # 50-250\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]  # '<pad>' -> 1\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "OUTPUT_DIM = 1  # No of labels\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'>>> The model has {num_parameters:,} trainable parameters')\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (conv_0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "  (conv_1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "  (conv_2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imsBloKKqDDX",
        "outputId": "c3d613a7-5782-439a-b51d-9f8d7d4c9d80"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).unsqueeze(1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.conv_0(ts).squeeze(-1)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.avg_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 1, 12, 100])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5169],\n",
              "        [0.4944]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWWFdHzChySQ"
      },
      "source": [
        "# CNN model for flexible convolutional layers\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.convs = nn.ModuleList([nn.Conv2d(1, n_filters, (fsize, embedding_dim)) for fsize in filter_sizes])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_filters*len(filter_sizes), output_dim)\n",
        "  \n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "    # print(text_ts.shape)\n",
        "    \n",
        "    embedded = self.embedding(text_ts).unsqueeze(1)\n",
        "    # embedded = [batch size, 1, sent len, emb dim]\n",
        "\n",
        "    conved = [F.relu(conv(embedded)).squeeze(-1) for conv in self.convs]\n",
        "    # conved = [batch size, n_filters, sent len - filter size + 1]\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[-1]).squeeze(-1) for conv in conved]\n",
        "    # pooled = [batch size, n_filters]\n",
        "\n",
        "    cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "    # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, 1]\n",
        "\n",
        "    return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYqx53PV2mx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d860698-427e-4bdc-ae9e-35c39761f3d1"
      },
      "source": [
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'>>> The model has {num_parameters:,} trainable parameters')\n",
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrKpr7m8lh4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe381e76-3de2-48fc-b11c-fabeea9d0a0f"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).unsqueeze(1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.convs[0](ts).squeeze(-1)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.avg_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 1, 12, 100])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5159],\n",
              "        [0.5477]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA-hnGUOW4C8"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}