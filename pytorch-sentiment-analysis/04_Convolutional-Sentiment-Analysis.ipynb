{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Convolutional-Sentiment-Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGpy3rvL1_5",
        "outputId": "b646fef9-fed6-44d4-9e29-6601ac6c202c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data, datasets\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import spacy\n",
        "\n",
        "\n",
        "torch.__version__, torchtext.__version__, spacy.__version__, np.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.8.0+cu101', '0.9.0', '2.2.4', '1.19.5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I39JKY87WzB9"
      },
      "source": [
        "## Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xmBt5IAbCKq",
        "outputId": "7ddbede7-14cb-44d3-ba35-19fbe5cc4e17"
      },
      "source": [
        "%%time\n",
        "\n",
        "# set random seed for reproducibility\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# download and split dataset (train, valid, test)\n",
        "TEXT = data.Field(\n",
        "    tokenize='spacy', tokenizer_language='en_core_web_sm', batch_first=True\n",
        ")\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:09<00:00, 8.56MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 41s, sys: 10.9 s, total: 1min 52s\n",
            "Wall time: 2min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es19mu23RL4j",
        "outputId": "4c81c219-7dde-4e7d-9e92-d748c2a74ab6"
      },
      "source": [
        "# check the type and size of dataset\n",
        "print(f'>>> type : {type(train_data)}')\n",
        "print(f'>>> Number of training examples: {len(train_data)}')   # 17500 (35%)\n",
        "print(f'>>> Number of validation examples: {len(valid_data)}') # 7500  (15%)\n",
        "print(f'>>> Number of testing examples: {len(test_data)}')     # 25000 (50%)\n",
        "print()\n",
        "\n",
        "# check one sample data\n",
        "tmp_ex = train_data.examples[0]\n",
        "tmp_dict = vars(tmp_ex)\n",
        "print('< example data >')\n",
        "print('>>> type :', type(tmp_ex))\n",
        "for key in tmp_dict:\n",
        "  print(f'>>> {key} : {tmp_dict[key]}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> type : <class 'torchtext.legacy.data.dataset.Dataset'>\n",
            ">>> Number of training examples: 17500\n",
            ">>> Number of validation examples: 7500\n",
            ">>> Number of testing examples: 25000\n",
            "\n",
            "< example data >\n",
            ">>> type : <class 'torchtext.legacy.data.example.Example'>\n",
            ">>> text : ['This', 'really', 'is', 'the', 'most', 'dreadful', 'film', 'I', 'have', 'ever', 'seen', '.', 'I', 'simply', 'have', 'no', 'idea', 'how', 'anyone', 'has', 'the', 'audacity', 'to', 'put', 'this', 'on', 'release.<br', '/><br', '/>The', 'production', 'standards', 'are', 'atrocious', '.', 'There', 'is', 'no', 'pretence', 'here', 'at', 'cinematography', '.', 'The', 'camera', 'work', ',', 'scripting', ',', 'acting', 'and', 'sound', 'are', 'unbelievably', 'crass', '.', 'I', 'think', 'there', 'is', 'a', 'plot', ',', 'but', 'it', 'could', 'have', 'been', 'done', 'in', '10', 'minutes', 'sparing', 'us', 'the', 'time', 'to', 'watch', 'it', '.', 'The', 'hysterical', 'neurotic', 'girls', 'at', 'the', 'centre', 'of', 'this', 'piece', 'have', 'no', 'credibility', 'whatsoever.<br', '/><br', '/>I', 'would', 'urge', 'anyone', 'to', 'avoid', 'spending', 'any', 'time', 'or', 'money', 'on', 'this', 'Title', '.', 'It', 'is', 'truly', 'atrocious.<br', '/><br', '/>JDD', '-', '14', 'December', '2008']\n",
            ">>> label : neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVOnakpiP1T-",
        "outputId": "d2803c20-894d-4929-a4d4-faf43b920d3a"
      },
      "source": [
        "%%time\n",
        "\n",
        "# build vocabulary\n",
        "MAX_VOCAB_SIZE = 25_000\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "print('\\n')\n",
        "print(f\">>> Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\">>> Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")\n",
        "print(f\">>> Top 20 common tokens :{TEXT.vocab.freqs.most_common(20)}\")\n",
        "print()\n",
        "print('<itos and stoi>')\n",
        "print('>>> itos :', TEXT.vocab.itos[:10])\n",
        "print('>>> stoi :', LABEL.vocab.stoi)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:43, 5.29MB/s]                           \n",
            "100%|█████████▉| 398959/400000 [00:17<00:00, 23810.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            ">>> Unique tokens in TEXT vocabulary: 25002\n",
            ">>> Unique tokens in LABEL vocabulary: 2\n",
            ">>> Top 20 common tokens :[('the', 203553), (',', 192851), ('.', 165942), ('and', 109542), ('a', 109361), ('of', 100998), ('to', 93822), ('is', 76414), ('in', 61317), ('I', 54608), ('it', 53658), ('that', 49367), ('\"', 44716), (\"'s\", 43358), ('this', 42482), ('-', 36954), ('/><br', 35543), ('was', 35014), ('as', 30281), ('with', 29947)]\n",
            "\n",
            "<itos and stoi>\n",
            ">>> itos : ['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
            ">>> stoi : defaultdict(None, {'neg': 0, 'pos': 1})\n",
            "CPU times: user 40.5 s, sys: 4.9 s, total: 45.4 s\n",
            "Wall time: 3min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "vB58J1OUQZXr",
        "outputId": "3e4d620a-2ec3-49c3-ffb9-6412e847490f"
      },
      "source": [
        "# create the iterators\n",
        "BATCH_SIZE = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device\n",
        ")\n",
        "\n",
        "display(device, type(train_iterator), len(train_iterator), len(train_data)/BATCH_SIZE)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "torchtext.legacy.data.iterator.BucketIterator"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "273.4375"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0Ulm3zW3hX"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDyjWvlThyW-"
      },
      "source": [
        "# CNN model for fixed number of convolutional layers (3 layers)\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.conv_0 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
        "    self.conv_1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
        "    self.conv_2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
        "  \n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "\n",
        "    embedded = self.embedding(text_ts)\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    # embedded = [batch size, 1, sent len, emb dim]\n",
        "\n",
        "    conv0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
        "    conv1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
        "    conv2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
        "    # conv = [batch size, n_filters, sent len-filter_sizes[n]+1]\n",
        "\n",
        "    pool0 = F.max_pool1d(conv0, conv0.shape[2]).squeeze(2)\n",
        "    pool1 = F.max_pool1d(conv1, conv1.shape[2]).squeeze(2)\n",
        "    pool2 = F.max_pool1d(conv2, conv2.shape[2]).squeeze(2)\n",
        "    # pool = [batch size, n_filters]\n",
        "\n",
        "    cat = self.dropout(torch.cat((pool0, pool1, pool2), dim=1))\n",
        "    # cat = [batch size, n_filters*len(filter_sizes)]\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, output dim]\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOH7cgxzqDDR",
        "outputId": "d323bb1e-a32c-4372-9040-0ed5c477b265"
      },
      "source": [
        "# function for model summary\n",
        "def model_summary(model):\n",
        "  num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  print(f'>>> The model has {num_parameters:,} trainable parameters')\n",
        "  print(model)\n",
        "\n",
        "\n",
        "# generate model & summary\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100  # 50-250\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]  # '<pad>' -> 1\n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "OUTPUT_DIM = 1  # No of labels\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "model_summary(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (conv_0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "  (conv_1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "  (conv_2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imsBloKKqDDX",
        "outputId": "c61606f4-23da-4011-f935-c9725368265c"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).unsqueeze(1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.conv_0(ts).squeeze(-1)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.max_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 1, 12, 100])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5602],\n",
              "        [0.5909]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWWFdHzChySQ"
      },
      "source": [
        "# CNN model for flexible convolutional layers\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, n_filters, filter_sizes, output_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.convs = nn.ModuleList([nn.Conv2d(1, n_filters, (fsize, embedding_dim)) for fsize in filter_sizes])\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_filters*len(filter_sizes), output_dim)\n",
        "  \n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "    \n",
        "    embedded = self.embedding(text_ts).unsqueeze(1)\n",
        "    # [batch size, 1, sent len, emb dim]\n",
        "\n",
        "    conved = [F.relu(conv(embedded)).squeeze(-1) for conv in self.convs]\n",
        "    # conved = [batch size, n_filters, sent len - filter size + 1]\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[-1]).squeeze(-1) for conv in conved]\n",
        "    # pooled = [batch size, n_filters]\n",
        "\n",
        "    cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "    # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, 1]\n",
        "\n",
        "    return out"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYqx53PV2mx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9964419a-fe95-45ff-c248-31e69ed45e00"
      },
      "source": [
        "# generate model & summary\n",
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "model_summary(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrKpr7m8lh4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f256c68-4dc1-48f7-f412-320e0a9c82f5"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).unsqueeze(1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.convs[0](ts).squeeze(-1)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.max_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 1, 12, 100])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4980],\n",
              "        [0.4657]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA-hnGUOW4C8"
      },
      "source": [
        "# 1-Dimensional CNN model for flexible convolutional layers\n",
        "class CNN1d(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, pad_idx, output_dim, n_filters, filter_sizes, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, pad_idx)\n",
        "    self.convs = nn.ModuleList([nn.Conv1d(in_channels=embedding_dim, out_channels=n_filters, kernel_size=fs)\n",
        "                                for fs in filter_sizes])\n",
        "    self.droptout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
        "\n",
        "  def forward(self, text_ts):\n",
        "    # text_ts = [batch size, sent len]\n",
        "\n",
        "    embedded = self.embedding(text_ts).permute(0, 2, 1)\n",
        "    # embedded = [batch size, emb dim, sent len]\n",
        "\n",
        "    conved = [conv(embedded) for conv in self.convs]\n",
        "    # conved = [batch size, n_filters, sent len - filter_sizes[0] + 1]\n",
        "\n",
        "    pooled = [F.max_pool1d(c, c.shape[-1]).squeeze(-1) for c in conved]\n",
        "    # pooled = [batch size, n_filters]\n",
        "\n",
        "    cat = self.droptout(torch.cat(pooled, dim=1))\n",
        "    # cat = [batch size, n_filters * len(filter_sizes)]\n",
        "\n",
        "    out = self.fc(cat)\n",
        "    # out = [batch size, 1]\n",
        "\n",
        "    return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47gb-Q3zFKgt",
        "outputId": "25c600ac-84e7-4f7c-a4ac-4d8d53447626"
      },
      "source": [
        "# generate model & summary\n",
        "model = CNN1d(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "model_summary(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> The model has 2,620,801 trainable parameters\n",
            "CNN1d(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
            "    (1): Conv1d(100, 100, kernel_size=(4,), stride=(1,))\n",
            "    (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
            "  )\n",
            "  (droptout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrxY79uFH6jd",
        "outputId": "104d04b0-2118-4e1e-8478-ecba84182504"
      },
      "source": [
        "# test tensor shape in each step\n",
        "ts = torch.randint(low=1, high=250, size=(2, 12))\n",
        "print('>>> text_ts =', ts.shape)\n",
        "ts = model.embedding(ts).permute(0, 2, 1)\n",
        "print('>>> embedded =', ts.shape)\n",
        "ts = model.convs[0](ts)\n",
        "print('>>> conved[0] =', ts.shape)\n",
        "ts = F.max_pool1d(ts, ts.shape[-1]).squeeze(-1)\n",
        "print('>>> pooled[0] =', ts.shape)\n",
        "ts = torch.cat([ts]*3, dim=1)\n",
        "print('>>> cat =', ts.shape)\n",
        "ts = model.fc(ts)\n",
        "print('>>> out =', ts.shape)\n",
        "ts.sigmoid()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> text_ts = torch.Size([2, 12])\n",
            ">>> embedded = torch.Size([2, 100, 12])\n",
            ">>> conved[0] = torch.Size([2, 100, 10])\n",
            ">>> pooled[0] = torch.Size([2, 100])\n",
            ">>> cat = torch.Size([2, 300])\n",
            ">>> out = torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6715],\n",
              "        [0.6552]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "docsyRD_FKmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a357f915-baf2-459d-c2f9-5f7e643e4476"
      },
      "source": [
        "# generate final model\n",
        "model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "            filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "\n",
        "\n",
        "# check original weights\n",
        "original_weights = model.embedding.weight.data\n",
        "print('>>> original initial weights :\\n', original_weights.shape)\n",
        "print(original_weights)\n",
        "\n",
        "# replace initial weights of embedding layer with pre-trained embeddings\n",
        "model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
        "\n",
        "# replace initial weights of unk & pad tokens with zeros\n",
        "UNK_IDX = TEXT.vocab.unk_index  # '<unk>' -> 0\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "# check replaced weights\n",
        "print('\\n>>> replaced initial weights :\\n', model.embedding.weight.data.shape)\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> original initial weights :\n",
            " torch.Size([25002, 100])\n",
            "tensor([[ 1.3254, -2.3170, -0.3583,  ..., -0.7454, -2.2021, -0.1801],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.9172, -0.3920, -0.0956,  ..., -0.0722,  0.4056,  1.5364],\n",
            "        ...,\n",
            "        [ 0.6830,  0.3327,  2.1350,  ...,  0.1265, -1.5342,  0.4619],\n",
            "        [ 1.2645,  2.6647,  0.6182,  ..., -1.9697, -0.3327, -1.2851],\n",
            "        [ 1.8781,  0.3646, -1.1882,  ...,  1.2935,  0.2440,  0.9102]])\n",
            "\n",
            ">>> replaced initial weights :\n",
            " torch.Size([25002, 100])\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.4772,  0.7192, -0.4791,  ..., -0.4089,  0.3340,  0.2413],\n",
            "        [ 0.2382,  0.3403,  0.3520,  ..., -0.7629,  0.7094,  0.7381],\n",
            "        [ 0.5302, -0.8394,  0.3944,  ..., -0.6926, -0.1440,  0.2929]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgkDwlvvZAC1"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ5N8590p9iU"
      },
      "source": [
        "# function for calculating binary accuracy\n",
        "def binary_accuracy(preds, y):\n",
        "  pred_class = preds.sigmoid().round()\n",
        "  acc = (pred_class == y).float().mean()\n",
        "  return acc\n",
        "\n",
        "\n",
        "# function for training in each epoch\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    pred = model(batch.text).squeeze(1)\n",
        "    loss = criterion(pred, batch.label)\n",
        "    acc = binary_accuracy(pred, batch.label)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss\n",
        "    epoch_acc  += acc\n",
        "\n",
        "  return epoch_loss/len(iterator), epoch_acc/len(iterator)\n",
        "\n",
        "\n",
        "# function for evaluation (vaildation or test)\n",
        "def evaluate(model, iterator, criterion):\n",
        "  loss = 0\n",
        "  acc = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      pred = model(batch.text).squeeze(1)\n",
        "      loss += criterion(pred, batch.label)\n",
        "      acc += binary_accuracy(pred, batch.label)\n",
        "  return loss/len(iterator), acc/len(iterator)\n",
        "\n",
        "\n",
        "# function for calculating min, sec from start & end time\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time/60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN7kGTj7ZNhW",
        "outputId": "b41fff95-c155-423d-bc7a-2d1a69b9028c"
      },
      "source": [
        "%%time\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "outfile_dir = 'tut3-model.pt'\n",
        "\n",
        "n_epoch = 5\n",
        "best_val_loss = float('inf')\n",
        "for epoch in range(n_epoch):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  if valid_loss < best_val_loss:\n",
        "    torch.save(model.state_dict(), outfile_dir)\n",
        "    print('>>> Saved best model in epoch', epoch+1)\n",
        "\n",
        "  print(f'Epoch : {epoch+1:02}  |  Epoch time : {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss : {train_loss:.3f}  |  Train Acc : {train_acc*100:.2f}%')\n",
        "  print(f'\\tValid Loss : {valid_loss:.3f}  |  Valid Acc : {valid_acc*100:.2f}%')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 398959/400000 [00:30<00:00, 23810.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">>> Saved best model in epoch 1\n",
            "Epoch : 01  |  Epoch time : 14m 16s\n",
            "\tTrain Loss : 0.653  |  Train Acc : 61.05%\n",
            "\tValid Loss : 0.510  |  Valid Acc : 77.96%\n",
            ">>> Saved best model in epoch 2\n",
            "Epoch : 02  |  Epoch time : 14m 40s\n",
            "\tTrain Loss : 0.427  |  Train Acc : 80.46%\n",
            "\tValid Loss : 0.360  |  Valid Acc : 85.04%\n",
            ">>> Saved best model in epoch 3\n",
            "Epoch : 03  |  Epoch time : 14m 25s\n",
            "\tTrain Loss : 0.303  |  Train Acc : 87.55%\n",
            "\tValid Loss : 0.323  |  Valid Acc : 85.90%\n",
            ">>> Saved best model in epoch 4\n",
            "Epoch : 04  |  Epoch time : 14m 25s\n",
            "\tTrain Loss : 0.214  |  Train Acc : 91.77%\n",
            "\tValid Loss : 0.318  |  Valid Acc : 87.09%\n",
            ">>> Saved best model in epoch 5\n",
            "Epoch : 05  |  Epoch time : 14m 26s\n",
            "\tTrain Loss : 0.153  |  Train Acc : 94.47%\n",
            "\tValid Loss : 0.336  |  Valid Acc : 86.77%\n",
            "CPU times: user 1h 12min 6s, sys: 19.5 s, total: 1h 12min 25s\n",
            "Wall time: 1h 12min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HV7KVv5a4zp"
      },
      "source": [
        "## Load and Test saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-npGd975ZNm9",
        "outputId": "2c339b19-ec5a-46fa-9386-a02093b691c2"
      },
      "source": [
        "%%time\n",
        "\n",
        "# function for checking weight equality\n",
        "def check_weights(model1, model2):\n",
        "  flag = True\n",
        "  for p1, p2 in zip(model1.parameters(), model2.parameters()):\n",
        "    if not p1.data.equal(p2.data):\n",
        "      flag = False\n",
        "  return flag\n",
        "\n",
        "# load model\n",
        "loaded_model = CNN(vocab_size=INPUT_DIM, embedding_dim=EMBEDDING_DIM, pad_idx=PAD_IDX, n_filters=N_FILTERS,\n",
        "                   filter_sizes=FILTER_SIZES, output_dim=OUTPUT_DIM, dropout=DROPOUT).to(device)\n",
        "loaded_model.load_state_dict(torch.load(outfile_dir))\n",
        "\n",
        "# check weight equality\n",
        "print('>>> All weights are equal') if check_weights(model, loaded_model) else print('>>> WARNING!!! Not equal wieghts!')\n",
        "\n",
        "# test model performance\n",
        "test_loss, test_acc = evaluate(loaded_model, test_iterator, criterion)\n",
        "print(f'>>> Test Loss : {test_loss:.3f}  |  Test Acc : {test_acc*100:.2f}%')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> All weights are equal\n",
            ">>> Test Loss : 0.385  |  Test Acc : 84.46%\n",
            "CPU times: user 1min 54s, sys: 413 ms, total: 1min 54s\n",
            "Wall time: 1min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}