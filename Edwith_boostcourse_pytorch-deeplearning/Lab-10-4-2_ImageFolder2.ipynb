{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-10-4-2_ImageFolder2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwbXUJcNiVLp",
        "outputId": "ae1e3ac6-a2ce-4b79-97f4-1471ea7c1979"
      },
      "source": [
        "# Download Data\r\n",
        "!git clone https://github.com/deeplearningzerotoall/PyTorch.git\r\n",
        "!mv PyTorch/custom_data/origin_data/ ./"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch'...\n",
            "remote: Enumerating objects: 1899, done.\u001b[K\n",
            "remote: Total 1899 (delta 0), reused 0 (delta 0), pack-reused 1899\u001b[K\n",
            "Receiving objects: 100% (1899/1899), 80.33 MiB | 27.88 MiB/s, done.\n",
            "Resolving deltas: 100% (242/242), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E-LwOBwpoTW",
        "outputId": "bee212fd-ffb2-4c5b-acbd-af4f77c5b2c7"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "import random\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "import os\r\n",
        "\r\n",
        "# check device\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "# set seed for reproducibility\r\n",
        "random.seed(777)\r\n",
        "torch.manual_seed(777)\r\n",
        "if device == 'cuda':\r\n",
        "    torch.cuda.manual_seed_all(777)\r\n",
        "\r\n",
        "torch.__version__, device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.7.0+cu101', 'cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NzW7OMbp2Ft"
      },
      "source": [
        "## ImageFolder\r\n",
        "- 원본 사진이 256x512 사이즈의 고해상도 사진이므로, 용량을 낮추기 위해 불러올 때 64x128 사이즈로 변환\r\n",
        "- torchvision.transforms.Compose() 를 사용하면 여러 단계의 transform을 묶어 한 번에 적용 가능\r\n",
        "<br><br>\r\n",
        "\r\n",
        "## "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMDJsQnGj5CS",
        "outputId": "1b313d2e-5178-4bc6-deb6-08fbb8e257b5"
      },
      "source": [
        "trans = transforms.Compose([\r\n",
        "    transforms.Resize((64, 128)),\r\n",
        "    transforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "train_data = torchvision.datasets.ImageFolder(root='origin_data/', transform=trans)\r\n",
        "data_loader = DataLoader(train_data, batch_size=10, shuffle=True)\r\n",
        "\r\n",
        "train_data[0][0].shape, data_loader"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 64, 128]),\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7fdfab596150>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOG4njPsx4Z4",
        "outputId": "23e4c553-c95b-49f1-afa7-2fcd1a835820"
      },
      "source": [
        "for data in data_loader:\r\n",
        "  print(len(data), type(data))\r\n",
        "  print(data[0].shape, data[1].shape)\r\n",
        "  print(data[1])\r\n",
        "  break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 <class 'list'>\n",
            "torch.Size([10, 3, 64, 128]) torch.Size([10])\n",
            "tensor([0, 1, 1, 0, 0, 1, 0, 1, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK8_sQU5lGnO"
      },
      "source": [
        "class CNN(torch.nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(CNN, self).__init__()\r\n",
        "    self.layer1 = nn.Sequential(\r\n",
        "        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\r\n",
        "    )\r\n",
        "    self.layer2 = nn.Sequential(\r\n",
        "        nn.Conv2d(6, 16, 5, 1),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(2, 2),\r\n",
        "    )\r\n",
        "    self.layer3 = nn.Sequential(\r\n",
        "        nn.Linear(in_features=16*13*29, out_features=120, bias=True),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(120, 2)\r\n",
        "    )\r\n",
        "  \r\n",
        "  def forward(self, x, verbose=False):\r\n",
        "    def report_shape(output, verbose=verbose):\r\n",
        "      if verbose:\r\n",
        "        print(output.shape)\r\n",
        "\r\n",
        "    output = self.layer1(x)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    output = self.layer2(output)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    output = output.view(output.shape[0], -1)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    output = self.layer3(output)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    return output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99EcWdnwu62e",
        "outputId": "761b537c-0052-4f30-9315-fb7864811fd1"
      },
      "source": [
        "# testing - checking output shape of each layer\r\n",
        "net = CNN().to(device)\r\n",
        "test_in = torch.Tensor(size=(10, 3, 64, 128)).to(device)\r\n",
        "test_out = net.forward(test_in, verbose=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 6, 30, 62])\n",
            "torch.Size([10, 16, 13, 29])\n",
            "torch.Size([10, 6032])\n",
            "torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKG1Y5U7wBda",
        "outputId": "7649e52e-6f1f-44ee-85b4-1eff1107006b"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "# training\r\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)\r\n",
        "criterion = nn.CrossEntropyLoss().to(device)\r\n",
        "\r\n",
        "n_epochs = 5\r\n",
        "num_batch = len(data_loader)\r\n",
        "\r\n",
        "for epoch in range(n_epochs):\r\n",
        "  avg_cost = 0\r\n",
        "  for idx, data in enumerate(data_loader):\r\n",
        "    value, label = data[0].to(device), data[1].to(device)\r\n",
        "\r\n",
        "    hypothesis = net.forward(value)\r\n",
        "    cost = criterion(hypothesis, label)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    avg_cost += cost/num_batch\r\n",
        "  print(f'epoch : {epoch+1:3}  |  cost : {avg_cost:10.6f}')\r\n",
        "print('>>> Train Finished!')\r\n",
        "\r\n",
        "# save trained weights\r\n",
        "os.makedirs('model', exist_ok=True)\r\n",
        "torch.save(net, 'model/model.pth')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :   1  |  cost :   0.430994\n",
            "epoch :   2  |  cost :   0.002398\n",
            "epoch :   3  |  cost :   0.000228\n",
            "epoch :   4  |  cost :   0.000036\n",
            "epoch :   5  |  cost :   0.000010\n",
            ">>> Train Finished!\n",
            "CPU times: user 7.96 s, sys: 154 ms, total: 8.11 s\n",
            "Wall time: 8.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_GT5EGY0EBJ"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}