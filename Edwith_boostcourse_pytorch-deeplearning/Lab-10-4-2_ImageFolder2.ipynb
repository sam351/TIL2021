{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-10-4-2_ImageFolder2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwbXUJcNiVLp",
        "outputId": "bd469004-3c1a-4b9a-e1a9-a33c4d8128e8"
      },
      "source": [
        "# Download Data\r\n",
        "!git clone https://github.com/deeplearningzerotoall/PyTorch.git\r\n",
        "!mv PyTorch/custom_data/origin_data/ ./\r\n",
        "!mv PyTorch/custom_data/test_data/ ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorch'...\n",
            "remote: Enumerating objects: 1899, done.\u001b[K\n",
            "remote: Total 1899 (delta 0), reused 0 (delta 0), pack-reused 1899\u001b[K\n",
            "Receiving objects: 100% (1899/1899), 80.33 MiB | 44.04 MiB/s, done.\n",
            "Resolving deltas: 100% (242/242), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E-LwOBwpoTW",
        "outputId": "b4e556c4-fa6c-42db-f33d-6ec9986a7607"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "import random\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "import os\r\n",
        "\r\n",
        "# check device\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "# set seed for reproducibility\r\n",
        "random.seed(777)\r\n",
        "torch.manual_seed(777)\r\n",
        "if device == 'cuda':\r\n",
        "    torch.cuda.manual_seed_all(777)\r\n",
        "\r\n",
        "torch.__version__, device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.7.0+cu101', 'cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NzW7OMbp2Ft"
      },
      "source": [
        "## ImageFolder\r\n",
        "- 원본 사진이 256x512 사이즈의 고해상도 사진이므로, 용량을 낮추기 위해 불러올 때 64x128 사이즈로 변환\r\n",
        "- torchvision.transforms.Compose() 를 사용하면 여러 단계의 transform을 묶어 한 번에 적용 가능\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMDJsQnGj5CS",
        "outputId": "6295ae4c-c1b1-426e-fe43-b6a5480d48c7"
      },
      "source": [
        "# Load train dataset\r\n",
        "trans = transforms.Compose([\r\n",
        "    transforms.Resize((64, 128)),\r\n",
        "    transforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "train_data = torchvision.datasets.ImageFolder(root='origin_data/', transform=trans)\r\n",
        "data_loader = DataLoader(train_data, batch_size=10, shuffle=True)\r\n",
        "\r\n",
        "train_data[0][0].shape, data_loader"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 64, 128]),\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7f4ce86b2c50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQXAVWWo9KEu"
      },
      "source": [
        "## Save & Load model (state_dict)\r\n",
        "- `torch.save(model.state_dict(), 'model.pth')` 명령어를 사용해 학습된 모델 가중치(파라미터) 저장 가능\r\n",
        "- 저장된 모델과 동일한 아키텍쳐로 만들어진 모델 객체를 초기화한 후, `new_model.load_state_dict(torch.load('model.pth'))` 명령어를 사용해 기존에 학습했던 모델 가중치(파라미터) 재사용 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK8_sQU5lGnO"
      },
      "source": [
        "# Generate layers\r\n",
        "class CNN(torch.nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(CNN, self).__init__()\r\n",
        "    self.layer1 = nn.Sequential(\r\n",
        "        nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\r\n",
        "    )\r\n",
        "    self.layer2 = nn.Sequential(\r\n",
        "        nn.Conv2d(6, 16, 5, 1),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(2, 2),\r\n",
        "    )\r\n",
        "    self.layer3 = nn.Sequential(\r\n",
        "        nn.Linear(in_features=16*13*29, out_features=120, bias=True),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.Linear(120, 2)\r\n",
        "    )\r\n",
        "  \r\n",
        "  def forward(self, x, verbose=False):\r\n",
        "    def report_shape(output, verbose=verbose):\r\n",
        "      if verbose:\r\n",
        "        print(output.shape)\r\n",
        "\r\n",
        "    output = self.layer1(x)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    output = self.layer2(output)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    output = output.view(output.shape[0], -1)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    output = self.layer3(output)\r\n",
        "    report_shape(output)\r\n",
        "    \r\n",
        "    return output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99EcWdnwu62e",
        "outputId": "4bb00c81-bea4-42a9-9a5a-0911c8f1ac47"
      },
      "source": [
        "# Test layer outputs - checking output shape of each layer\r\n",
        "net = CNN().to(device)\r\n",
        "test_in = torch.Tensor(size=(10, 3, 64, 128)).to(device)\r\n",
        "test_out = net.forward(test_in, verbose=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 6, 30, 62])\n",
            "torch.Size([10, 16, 13, 29])\n",
            "torch.Size([10, 6032])\n",
            "torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKG1Y5U7wBda",
        "outputId": "a731cb3b-1d6f-4241-b99f-ab9fe9a2c9cb"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "# Train model\r\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.00005)\r\n",
        "criterion = nn.CrossEntropyLoss().to(device)\r\n",
        "\r\n",
        "n_epochs = 5\r\n",
        "num_batch = len(data_loader)\r\n",
        "\r\n",
        "for epoch in range(n_epochs):\r\n",
        "  avg_cost = 0\r\n",
        "  for idx, data in enumerate(data_loader):\r\n",
        "    value, label = data[0].to(device), data[1].to(device)\r\n",
        "\r\n",
        "    hypothesis = net.forward(value)\r\n",
        "    cost = criterion(hypothesis, label)\r\n",
        "\r\n",
        "    optimizer.zero_grad()\r\n",
        "    cost.backward()\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    avg_cost += cost/num_batch\r\n",
        "  print(f'epoch : {epoch+1:3}  |  cost : {avg_cost:10.6f}')\r\n",
        "print('>>> Train Finished!')\r\n",
        "\r\n",
        "# Save trained weights (state_dict)\r\n",
        "os.makedirs('model', exist_ok=True)\r\n",
        "torch.save(net.state_dict(), 'model/model.pth')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch :   1  |  cost :   0.639913\n",
            "epoch :   2  |  cost :   0.462027\n",
            "epoch :   3  |  cost :   0.195709\n",
            "epoch :   4  |  cost :   0.064646\n",
            "epoch :   5  |  cost :   0.027660\n",
            ">>> Train Finished!\n",
            "CPU times: user 7.92 s, sys: 136 ms, total: 8.06 s\n",
            "Wall time: 8.12 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Im0heEj3J2T",
        "outputId": "a41c9f1e-7bfb-4384-bfc4-b2a217fbd1e3"
      },
      "source": [
        "# Load & Check model's state_dict\r\n",
        "new_net = CNN().to(device)\r\n",
        "new_net.load_state_dict(torch.load('model/model.pth'))\r\n",
        "new_net.eval()\r\n",
        "print()\r\n",
        "\r\n",
        "print(net.layer1[0])\r\n",
        "print(new_net.layer1[0], '\\n')\r\n",
        "\r\n",
        "print(net.layer1[0].weight[0][0][0])\r\n",
        "print(new_net.layer1[0].weight[0][0][0], '\\n')\r\n",
        "\r\n",
        "(net.layer1[0].weight == new_net.layer1[0].weight).all().item()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) \n",
            "\n",
            "tensor([-0.0934,  0.0012, -0.0192, -0.0234,  0.0909], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([-0.0934,  0.0012, -0.0192, -0.0234,  0.0909], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>) \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHyb3HId9dga"
      },
      "source": [
        "## Test model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nvAIZ7J4PXY"
      },
      "source": [
        "# Load test dataset\r\n",
        "trans = transforms.Compose([\r\n",
        "    transforms.Resize((64, 128)),\r\n",
        "    transforms.ToTensor(),\r\n",
        "])\r\n",
        "\r\n",
        "test_data = torchvision.datasets.ImageFolder(root='test_data/', transform=trans)\r\n",
        "data_loader_test = DataLoader(test_data, batch_size=len(test_data))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6piXa4Bj5xXV",
        "outputId": "56b9489d-2df9-40cc-a4e4-1978179c8bb2"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "# Test model with test dataset\r\n",
        "with torch.no_grad():\r\n",
        "  for data in data_loader_test:\r\n",
        "    value, label = data[0].to(device), data[1].to(device)\r\n",
        "    \r\n",
        "    prediction = new_net.forward(value).argmax(1)\r\n",
        "    acc = (prediction == label).float().mean()\r\n",
        "    print(f'>>> Test accuracy : {acc:6.4f}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Test accuracy : 1.0000\n",
            "CPU times: user 2.53 s, sys: 21.2 ms, total: 2.56 s\n",
            "Wall time: 2.56 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH6USFIv7CEW"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}