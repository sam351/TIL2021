{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_question-answering",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntcyeOEtMhEt"
      },
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk3ovz71AMnZ",
        "outputId": "6d64f22f-3fe6-4f1b-da13-75f286b2483e"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-ef3d59f4-ddf0-c0d1-c3db-d3180bbc33ab)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwpgQNHgMoBr"
      },
      "source": [
        "## Fine-tuning a model on a question-answering task\n",
        "This notebook will show to fine-tune one of the ðŸ¤— Transformers model to a question answering task, which is the task of extracting the answer to a question from a given context.\n",
        "<br><br>\n",
        "**Note** : This notebook finetunes models that answer question by taking a substring of a context, not by generating new text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCm4wcLICfve"
      },
      "source": [
        "# set main parameters\n",
        "squad_v2_flag = False\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "batch_size = 16\n",
        "\n",
        "# check execution time for whole code\n",
        "import time\n",
        "s_time = time.time()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFnuND9vO-G5",
        "outputId": "0dba93f4-5697-4941-9d85-7e3c3bbcd468"
      },
      "source": [
        "import datasets\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import collections\n",
        "import tqdm\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
        "\n",
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# datasets : 1.6.1  |  pd : 1.1.5  |  np : 1.19.5  |  tqdm : 4.41.1  |  transformers : 4.5.1  |  torch : 1.8.1+cu101\n",
        "print(f'datasets : {datasets.__version__}  |  pd : {pd.__version__}  |  np : {np.__version__}  |  tqdm : {tqdm.__version__}  |  transformers : {transformers.__version__}  |  torch : {torch.__version__}')\n",
        "print('device :', device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datasets : 1.6.1  |  pd : 1.1.5  |  np : 1.19.5  |  tqdm : 4.41.1  |  transformers : 4.5.1  |  torch : 1.8.1+cu101\n",
            "device : cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHrlxkxJO0pp"
      },
      "source": [
        "## 1. Loading the dataset & metric\n",
        "- We will use the ðŸ¤— Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.\n",
        "\n",
        "- ðŸ¤— Datasets library also provide `list_datasets()` function to get the list of all available datasets. There are about 21 datasets related to QA task.\n",
        "  - ref : https://huggingface.co/datasets/squad_kor_v1 (Korean squad_v1 by LG CNS)\n",
        "  - ref : https://huggingface.co/datasets/squad_kor_v2 (Korean squad_v2 by LG CNS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pamHnPYfFoTx",
        "outputId": "202e9e85-5d65-4f11-ad3e-3c826448613a"
      },
      "source": [
        "# check dataset list\n",
        "dset_list = datasets.list_datasets()\n",
        "qa_dset_list = [i for i in dset_list if 'quad' in i]\n",
        "\n",
        "print('>>> Total No of provided datasets :', len(dset_list))\n",
        "print('>>> No of QA datasets :', len(qa_dset_list))\n",
        "print(np.array([i for i in dset_list if 'quad' in i]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Total No of provided datasets : 849\n",
            ">>> No of QA datasets : 21\n",
            "['fquad' 'iapp_wiki_qa_squad' 'lc_quad' 'squad' 'squad_adversarial'\n",
            " 'squad_es' 'squad_it' 'squad_kor_v1' 'squad_kor_v2' 'squad_v1_pt'\n",
            " 'squad_v2' 'squadshifts' 'thaiqa_squad' 'xquad' 'xquad_r'\n",
            " 'lhoestq/custom_squad' 'lhoestq/squad' 'piEsposito/br-quad-2.0'\n",
            " 'piEsposito/br_quad_20' 'piEsposito/squad_20_ptbr'\n",
            " 'susumu2357/squad_v2_sv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "0eKAI8c5KzdJ",
        "outputId": "1dcf795c-3aeb-4475-9512-fa6a5474d74e"
      },
      "source": [
        "# load dataset & metric\n",
        "dset_dict = datasets.load_dataset('squad_v2' if squad_v2_flag else 'squad')\n",
        "metric = datasets.load_metric(\"squad_v2\" if squad_v2_flag else \"squad\")\n",
        "\n",
        "# check dataset\n",
        "print('\\n>>> dataset object :')\n",
        "display(dset_dict)\n",
        "print('\\n>>> sample data :')\n",
        "display(dset_dict['train'][0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">>> dataset object :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">>> sample data :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
              " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'id': '5733be284776f41900661182',\n",
              " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
              " 'title': 'University_of_Notre_Dame'}"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "Q8eKNWtLL7zP",
        "outputId": "f39b56a7-36c8-49d5-87e2-0497429a7dc9"
      },
      "source": [
        "# show random sample of a dataset\n",
        "def show_random_elements(dataset, num_examples=5):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    random.seed(42)\n",
        "    picks = random.sample(range(len(dataset)), k=num_examples)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))\n",
        "\n",
        "show_random_elements(dset_dict[\"train\"], 2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'answer_start': [346], 'text': ['Ovid']}</td>\n",
              "      <td>The meaning and origin of many archaic festivals baffled even Rome's intellectual elite, but the more obscure they were, the greater the opportunity for reinvention and reinterpretation â€” a fact lost neither on Augustus in his program of religious reform, which often cloaked autocratic innovation, nor on his only rival as mythmaker of the era, Ovid. In his Fasti, a long-form poem covering Roman holidays from January to June, Ovid presents a unique look at Roman antiquarian lore, popular customs, and religious practice that is by turns imaginative, entertaining, high-minded, and scurrilous; not a priestly account, despite the speaker's pose as a vates or inspired poet-prophet, but a work of description, imagination and poetic etymology that reflects the broad humor and burlesque spirit of such venerable festivals as the Saturnalia, Consualia, and feast of Anna Perenna on the Ides of March, where Ovid treats the assassination of the newly deified Julius Caesar as utterly incidental to the festivities among the Roman people. But official calendars preserved from different times and places also show a flexibility in omitting or expanding events, indicating that there was no single static and authoritative calendar of required observances. In the later Empire under Christian rule, the new Christian festivals were incorporated into the existing framework of the Roman calendar, alongside at least some of the traditional festivals.</td>\n",
              "      <td>5731ab21b9d445190005e44f</td>\n",
              "      <td>What poet wrote a long poem describing Roman religious holidays?</td>\n",
              "      <td>Religion_in_ancient_Rome</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'answer_start': [64], 'text': ['hydrocarbons']}</td>\n",
              "      <td>Hydrogen forms a vast array of compounds with carbon called the hydrocarbons, and an even vaster array with heteroatoms that, because of their general association with living things, are called organic compounds. The study of their properties is known as organic chemistry and their study in the context of living organisms is known as biochemistry. By some definitions, \"organic\" compounds are only required to contain carbon. However, most of them also contain hydrogen, and because it is the carbon-hydrogen bond which gives this class of compounds most of its particular chemical characteristics, carbon-hydrogen bonds are required in some definitions of the word \"organic\" in chemistry. Millions of hydrocarbons are known, and they are usually formed by complicated synthetic pathways, which seldom involve elementary hydrogen.</td>\n",
              "      <td>56e08b457aa994140058e5e3</td>\n",
              "      <td>What is the form of hydrogen and carbon called?</td>\n",
              "      <td>Hydrogen</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z3mmk1QFoWQ"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}