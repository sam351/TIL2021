{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec02-1. Simple Linear Regression",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUzhcZAsINs5"
      },
      "source": [
        "# Lec 02: Simple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMN1xDN7Lx4o"
      },
      "source": [
        "## 핵심키워드\r\n",
        "- 선형회귀(Linear Regression)\r\n",
        "- 가설(Hypothesis)\r\n",
        "- 비용함수(Cost function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX4g5ZUCIwi7"
      },
      "source": [
        "## Regression\r\n",
        "\"Regression toward the mean\" (Sir Francis Galton)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLcCspCaIw2j"
      },
      "source": [
        "## Linear Regression\r\n",
        "\"데이터를 가장 잘 대변하는 직선을 찾는 것\" (ex. y=ax+b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJdCdv9uIxCk"
      },
      "source": [
        "## Hypothesis (linear)\r\n",
        "- H(x) = Wx + b\r\n",
        "- 최선의 가설(W와 b)을 찾기 위해 Cost 활용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55oHeNh4IxPY"
      },
      "source": [
        "## Cost function\r\n",
        "- Error : H(x) - y (가설과 실제 데이터 사이의 차이)\r\n",
        "- 일반적으로 '개별 오차의 제곱값들의 평균(Mean Squared Error)'을 비용함수(Cost/Loss function)로 많이 사용\r\n",
        "- 학습(Learning)의 목표는 비용함수를 최소화하는 W와 b를 찾는 것"
      ]
    }
  ]
}