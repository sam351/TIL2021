{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec06-3. Softmax Regression and Classification in TensorFlow",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUzhcZAsINs5"
      },
      "source": [
        "# Lab 06-3: Softmax classifier 를 TensorFlow 로 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMN1xDN7Lx4o"
      },
      "source": [
        "## 핵심키워드\r\n",
        "- 다항 분류(Multinomial Classification)\r\n",
        "- 소프트맥스(Softmax)\r\n",
        "- 크로스 엔트로피(Cross-entropy)\r\n",
        "- 경사하강법(Gradient Descent)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggPVP7Coc-sI",
        "outputId": "af659575-ddcc-47fc-f7e9-38e1d69e998f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print(f'>>> original : tf - 2.4.0  |  np - 1.19.4')\r\n",
        "print(f'>>> present  : tf - {tf.__version__}  |  np - {np.__version__}')\r\n",
        "\r\n",
        "tf.random.set_seed(777)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> original : tf - 2.4.0  |  np - 1.19.4\n",
            ">>> present  : tf - 2.4.0  |  np - 1.19.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3oSE7X4bRh1"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV6taIhWy9os",
        "outputId": "66e017c5-a1c5-4ed0-95d9-3ff236f46934"
      },
      "source": [
        "x_data = np.array([[1, 2, 1, 1],\r\n",
        "                   [2, 1, 3, 2],\r\n",
        "                   [3, 1, 3, 4],\r\n",
        "                   [4, 1, 5, 5],\r\n",
        "                   [1, 7, 5, 5],\r\n",
        "                   [1, 2, 5, 6],\r\n",
        "                   [1, 6, 6, 6],\r\n",
        "                   [1, 7, 7, 7]], dtype=np.float32)\r\n",
        "y_data = np.array([[0, 0, 1],\r\n",
        "                   [0, 0, 1],\r\n",
        "                   [0, 0, 1],\r\n",
        "                   [0, 1, 0],\r\n",
        "                   [0, 1, 0],\r\n",
        "                   [0, 1, 0],\r\n",
        "                   [1, 0, 0],\r\n",
        "                   [1, 0, 0]], dtype=np.float32)\r\n",
        "nb_classes = y_data.shape[1]  # number of classes==3\r\n",
        "\r\n",
        "x_data.shape, y_data.shape, nb_classes"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8, 4), (8, 3), 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GevDNyWIitTB"
      },
      "source": [
        "## Softmax Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX6zVsXJhyCW",
        "outputId": "10c4ac76-bd43-4d4a-c41c-dcd26f1a863c"
      },
      "source": [
        "# Weight and bias setting\r\n",
        "W = tf.Variable(tf.random.normal((x_data.shape[1], nb_classes)))\r\n",
        "b = tf.Variable(tf.random.normal((nb_classes,)))\r\n",
        "\r\n",
        "print(W, b)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
            "array([[ 0.7706481 ,  0.37335402, -0.05576323],\n",
            "       [ 0.00358377, -0.5898363 ,  1.5702795 ],\n",
            "       [ 0.2460895 , -0.09918973,  1.4418385 ],\n",
            "       [ 0.3200988 ,  0.526784  , -0.7703731 ]], dtype=float32)> <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([-1.3080608 , -0.13253094,  0.5513761 ], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k94afnQJ08if",
        "outputId": "71ef8bed-a2d3-44a4-b030-e240ccc1e1df"
      },
      "source": [
        "# Train model\r\n",
        "def hypothesis(X, weight=W, bias=b):\r\n",
        "  Y = tf.matmul(X, W) + b\r\n",
        "  return tf.nn.softmax(Y)\r\n",
        "\r\n",
        "def cost_fn(X, Y):\r\n",
        "  logits = hypothesis(X)\r\n",
        "  cost = -tf.reduce_mean(tf.reduce_sum(tf.multiply(Y, tf.math.log(logits)), axis=1))\r\n",
        "  return cost\r\n",
        "\r\n",
        "def grad_fn(X, Y, weight=W, bias=b):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    logits = hypothesis(X)\r\n",
        "    cost = cost_fn(X, Y)\r\n",
        "    grads = tape.gradient(cost, [W, b])\r\n",
        "  return grads\r\n",
        "\r\n",
        "def fit(X, Y, weight=W, bias=b, epochs=2000, verbose=100):\r\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\r\n",
        "\r\n",
        "  print('epoch | cost')\r\n",
        "  for step in range(epochs):\r\n",
        "    step += 1\r\n",
        "    grads = grad_fn(X, Y, W, b)\r\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\r\n",
        "\r\n",
        "    if step == 1 or step % verbose == 0:\r\n",
        "      cost = cost_fn(X, Y)\r\n",
        "      print(f'{step:5.0f} | {cost:8.6f}')\r\n",
        "\r\n",
        "\r\n",
        "fit(x_data, y_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch | cost\n",
            "    1 | 2.849417\n",
            "  100 | 0.684151\n",
            "  200 | 0.613813\n",
            "  300 | 0.558205\n",
            "  400 | 0.508306\n",
            "  500 | 0.461059\n",
            "  600 | 0.415072\n",
            "  700 | 0.369636\n",
            "  800 | 0.324533\n",
            "  900 | 0.280720\n",
            " 1000 | 0.246752\n",
            " 1100 | 0.232798\n",
            " 1200 | 0.221645\n",
            " 1300 | 0.211476\n",
            " 1400 | 0.202164\n",
            " 1500 | 0.193606\n",
            " 1600 | 0.185714\n",
            " 1700 | 0.178415\n",
            " 1800 | 0.171645\n",
            " 1900 | 0.165350\n",
            " 2000 | 0.159483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnopYAFn6tnu",
        "outputId": "5dc11295-fcb3-43d6-c1ef-165f8e26c196"
      },
      "source": [
        "# Prediction Check\r\n",
        "pred = hypothesis(x_data)\r\n",
        "print(tf.argmax(pred, 1))\r\n",
        "print(tf.argmax(y_data, 1))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n",
            "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ChY6cX_zc5J"
      },
      "source": [
        "## Softmax Classification as a class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_q3qMRQzc5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0179a2-1342-47d2-ddcd-c981d8deff55"
      },
      "source": [
        "class softmax_classifier(tf.keras.Model):\r\n",
        "  def __init__(self, nb_features, nb_classes):\r\n",
        "    super(softmax_classifier, self).__init__()\r\n",
        "    self.W = tf.Variable(tf.random.normal((nb_features, nb_classes)))\r\n",
        "    self.b = tf.Variable(tf.random.normal((nb_classes,)))\r\n",
        "    pass\r\n",
        "\r\n",
        "  def softmax_regression(self, X):\r\n",
        "    pred = tf.matmul(X, self.W) + self.b\r\n",
        "    return tf.nn.softmax(pred)\r\n",
        "\r\n",
        "  def cost_fn(self, X, Y):\r\n",
        "    logits = self.softmax_regression(X)\r\n",
        "    cost = -tf.reduce_mean(tf.reduce_sum(tf.multiply(Y, tf.math.log(logits)), axis=1))\r\n",
        "    return cost\r\n",
        "\r\n",
        "  def grad_fn(self, X, Y):\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      logits = self.softmax_regression(X)\r\n",
        "      cost = self.cost_fn(X, Y)\r\n",
        "      grads = tape.gradient(cost, [self.W, self.b])\r\n",
        "    return grads\r\n",
        "\r\n",
        "  def fit(self, X, Y, epochs=2000, verbose=100):\r\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\r\n",
        "\r\n",
        "    print('epoch | cost')\r\n",
        "    for step in range(epochs):\r\n",
        "      step += 1\r\n",
        "      grads = self.grad_fn(X, Y)\r\n",
        "      optimizer.apply_gradients(grads_and_vars=zip(grads, [self.W, self.b]))\r\n",
        "\r\n",
        "      if step == 1 or step % verbose == 0:\r\n",
        "        cost = self.cost_fn(X, Y)\r\n",
        "        print(f'{step:5.0f} | {cost:8.6f}')\r\n",
        "\r\n",
        "\r\n",
        "model = softmax_classifier(nb_features=4, nb_classes=3)\r\n",
        "model.fit(x_data, y_data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch | cost\n",
            "    1 | 2.472669\n",
            "  100 | 0.639449\n",
            "  200 | 0.524868\n",
            "  300 | 0.463929\n",
            "  400 | 0.416868\n",
            "  500 | 0.375229\n",
            "  600 | 0.335701\n",
            "  700 | 0.296750\n",
            "  800 | 0.261106\n",
            "  900 | 0.242689\n",
            " 1000 | 0.229923\n",
            " 1100 | 0.218464\n",
            " 1200 | 0.208102\n",
            " 1300 | 0.198676\n",
            " 1400 | 0.190059\n",
            " 1500 | 0.182148\n",
            " 1600 | 0.174857\n",
            " 1700 | 0.168117\n",
            " 1800 | 0.161866\n",
            " 1900 | 0.156053\n",
            " 2000 | 0.150633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bvPG1wzdK6x",
        "outputId": "c76fcf57-56c7-475d-808b-c493d33a4c28"
      },
      "source": [
        "# Prediction Check\r\n",
        "pred = model.softmax_regression(x_data)\r\n",
        "print(tf.argmax(pred, 1))\r\n",
        "print(tf.argmax(y_data, 1))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n",
            "tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}