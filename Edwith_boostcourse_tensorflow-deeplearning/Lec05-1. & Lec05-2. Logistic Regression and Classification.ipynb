{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec05-1. & Lec05-2. Logistic Regression and Classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUzhcZAsINs5"
      },
      "source": [
        "# Lec 05-1: Logistic Regression/Classification 의 소개\r\n",
        "# Lec 05-2: Logistic Regression/Classification 의 cost 함수, 최소화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMN1xDN7Lx4o"
      },
      "source": [
        "## 핵심키워드\r\n",
        "- 로지스틱 회귀 / 분류(Logistic Regression / Classification)\r\n",
        "- 가설(Hypothesis)\r\n",
        "- 시그모이드 / 로지스틱(Sigmoid / Logistic)\r\n",
        "- 비용 함수(Cost function)\r\n",
        "- 최적화(Optimization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX4g5ZUCIwi7"
      },
      "source": [
        "## Binary Classification\r\n",
        "- Target feature(variable) is either 0 or 1\r\n",
        "- ex) Exam pass/fail, Spam/Not-spam, etc\r\n",
        "- To start with machine learning, the target must be encoded as [0, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLcCspCaIw2j"
      },
      "source": [
        "## Hypothesis Representation\r\n",
        "- The hypothesis of linear regression was $h_θ(x) = θ^T \\cdot X$. However, in binary classification, we need new type of hypothesis since the target is only 0 or 1.\r\n",
        "- **New Hypothesis** :\r\n",
        " - $ h_θ(x) = g(θ^T \\cdot X ) $\r\n",
        " - $ g(z) = 1/(1 + e^{-z}) $\r\n",
        "- g(z) function is **Sigmoid/Logistic function** whose output is between 0 and 1.\r\n",
        "- Using train data, we can get the appropriate **decision boundary** where the expected value (0 or 1) will be split.\r\n",
        "- the expected label would be 1 if the point of certain input data is over the decision boundary, and vice versa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjL3S8FIZJI8"
      },
      "source": [
        "## Cost Function & Optimization\r\n",
        "- The cost function of linear regression(MSE) would be non-convex when it's used in binary classification(Logistic regression), so we need new type of cost function.<br><br>\r\n",
        "$cost(h_θ(x), y) = -y\\log(h_θ(x)) - (1-y)\\log(1-h_θ(x))$\r\n",
        "<br><br>\r\n",
        "- The optimization method of linear regression can also be used in binary classification"
      ]
    }
  ]
}