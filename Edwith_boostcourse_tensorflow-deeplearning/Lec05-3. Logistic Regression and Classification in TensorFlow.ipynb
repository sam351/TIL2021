{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lec05-3. Logistic Regression and Classification in TensorFlow",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUzhcZAsINs5"
      },
      "source": [
        "# Lab 05-3: Logistic Regression/Classification 를 TensorFlow로 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMN1xDN7Lx4o"
      },
      "source": [
        "## 핵심키워드\r\n",
        "- 로지스틱 회귀 / 분류(Logistic Regression / Classification)\r\n",
        "- 가설(Hypothesis)\r\n",
        "- 시그모이드 / 로지스틱(Sigmoid / Logistic)\r\n",
        "- 비용 함수(Cost function)\r\n",
        "- 최적화(Optimization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggPVP7Coc-sI",
        "outputId": "d326d5c9-1c7d-4067-d66d-250c0dae9dfd"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "print(f'>>> original : tf - 2.4.0  |  np - 1.19.4')\r\n",
        "print(f'>>> present  : tf - {tf.__version__}  |  np - {np.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> original : tf - 2.4.0  |  np - 1.19.4\n",
            ">>> present  : tf - 2.4.0  |  np - 1.19.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3oSE7X4bRh1"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uGfqS4yVbSbq",
        "outputId": "dcefa197-1faa-42a1-c21f-fe4e02079667"
      },
      "source": [
        "# x_train = [[1., 2.],\r\n",
        "#           [2., 3.],\r\n",
        "#           [3., 1.],\r\n",
        "#           [4., 3.],\r\n",
        "#           [5., 3.],\r\n",
        "#           [6., 2.]]\r\n",
        "x_train = [[1., 2.],\r\n",
        "          [2., 2.5],\r\n",
        "          [4., 1.],\r\n",
        "          [3., 3.],\r\n",
        "          [5., 3.],\r\n",
        "          [6., 2.]]\r\n",
        "y_train = [[0.],\r\n",
        "          [0.],\r\n",
        "          [0.],\r\n",
        "          [1.],\r\n",
        "          [1.],\r\n",
        "          [1.]]\r\n",
        "\r\n",
        "x_test = [[5.,2.],\r\n",
        "          [4, 2],\r\n",
        "          [4, 3]]\r\n",
        "y_test = [[1.],\r\n",
        "          [1],\r\n",
        "          [1]]\r\n",
        "\r\n",
        "\r\n",
        "# Visualize data\r\n",
        "x1 = [i[0] for i in x_train]\r\n",
        "x2 = [i[1] for i in x_train]\r\n",
        "colors = [i[0]%3 for i in y_train]\r\n",
        "plt.scatter(x1, x2, c=colors, marker='^')\r\n",
        "\r\n",
        "x1_test = [i[0] for i in x_test]\r\n",
        "x2_test = [i[1] for i in x_test]\r\n",
        "plt.scatter(x1_test, x2_test, c='red')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GevDNyWIitTB"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX6zVsXJhyCW",
        "outputId": "ee5cdc3c-fa55-411b-b4a5-f977c205fcf7"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\r\n",
        "\r\n",
        "W = tf.Variable(tf.random.normal((2, 1)))\r\n",
        "b = tf.Variable(tf.random.normal((1,)))\r\n",
        "\r\n",
        "# hypothesis function\r\n",
        "def logistic_reg(features):\r\n",
        "  z = tf.matmul(features, W) + b\r\n",
        "  return tf.divide(1, 1 + tf.exp(-z))\r\n",
        "\r\n",
        "# cost function\r\n",
        "def loss_fn(hypothesis, labels):\r\n",
        "  loss = -tf.reduce_mean( tf.multiply(labels, tf.math.log(hypothesis)) + tf.multiply(1-labels, tf.math.log(1-hypothesis)) )\r\n",
        "  return loss\r\n",
        "\r\n",
        "# gradient function\r\n",
        "def grad(features, labels, W, b):\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    hypothesis = logistic_reg(features)\r\n",
        "    loss = loss_fn(hypothesis, labels)\r\n",
        "  W_grad, b_grad = tape.gradient(loss, [W, b])\r\n",
        "  return W_grad, b_grad\r\n",
        "\r\n",
        "# optimizer\r\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\r\n",
        "\r\n",
        "# metric\r\n",
        "def accuracy_fn(hypothesis, labels):\r\n",
        "  pred = tf.cast(hypothesis>0.5, dtype=tf.float32)\r\n",
        "  acc = tf.reduce_mean(tf.cast(tf.equal(pred, labels), dtype=tf.int32))\r\n",
        "  return acc\r\n",
        "\r\n",
        "# train model (update weights)\r\n",
        "for step in range(2000 + 1):  # epoch\r\n",
        "  for features, labels in iter(dataset):  # batch\r\n",
        "    grads = grad(features, labels, W, b)\r\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\r\n",
        "  \r\n",
        "  # verbose\r\n",
        "  if step%200==0:\r\n",
        "    loss = loss_fn(logistic_reg(features), labels)\r\n",
        "    print(f'Iter : {step:5} | Loss : {loss:6.4f}')\r\n",
        "\r\n",
        "test_acc = accuracy_fn(logistic_reg(x_test), y_test).numpy()\r\n",
        "print(f'Testset Accuracy : {test_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter :     0 | Loss : 1.0464\n",
            "Iter :   200 | Loss : 0.6107\n",
            "Iter :   400 | Loss : 0.5878\n",
            "Iter :   600 | Loss : 0.5683\n",
            "Iter :   800 | Loss : 0.5507\n",
            "Iter :  1000 | Loss : 0.5343\n",
            "Iter :  1200 | Loss : 0.5188\n",
            "Iter :  1400 | Loss : 0.5041\n",
            "Iter :  1600 | Loss : 0.4901\n",
            "Iter :  1800 | Loss : 0.4767\n",
            "Iter :  2000 | Loss : 0.4640\n",
            "Testset Accuracy : 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzK6lcPIt1X_"
      },
      "source": [
        "## Summary\r\n",
        "- Prediction process\r\n",
        " - X → $ z = θ^TX $ (Linear function) → $ g(z) =1/(1+ \\exp^{-z}) $ (Logistic function) → $ g(z) > 0.5 $ (Decision boundary) →  $ H(x) ∈ \\{0, 1\\} $\r\n",
        "<br><br>\r\n",
        "- Cost function\r\n",
        " - $ Cost(h_θ(x), y) = -y\\log(h_θ(x)) -(1-y)\\log(1-h_θ(x)) $\r\n",
        "<br><br>\r\n",
        "- The prediction process of logistic regression is similar to the process of each cell in basic Deep Neural Network, which will be discussed later in the course.\r\n",
        " - $ \\textrm{Input} → \\textrm{Linear Transformation} → \\textrm{Activation} → \\textrm{Output} $"
      ]
    }
  ]
}